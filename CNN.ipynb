{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPd1aMvygR816m5eq/Al8CA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kash2023k/Pytorch-Project1/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identifying 0-9 hand written numbers**"
      ],
      "metadata": {
        "id": "17QKVLGWvPgl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p-5MTdQKfToj"
      },
      "outputs": [],
      "source": [
        "# Importing all necessary library for CNN\n",
        "from keras.models import Sequential\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert MNIST image files into Tensor of 4 dimensions (# of images , height , width , color channels)\n",
        "\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "2gFEAS24hAi7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNzmUybthkEq",
        "outputId": "ecd7ab4a-61e8-4026-fa90-beec501b44e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 43.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.08MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.0MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.33MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Data\n",
        "\n",
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "5afGpKnNh_zw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofaqVW2UibTE",
        "outputId": "54130071-c486-4e78-9130-054fe6dabe5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: /cnn_data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDK6v6HbijuC",
        "outputId": "0d0ecc7c-6599-45ad-e6b6-74b5efba46b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /cnn_data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a batch size of images .. 10\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False) # We dont want to Shuffle"
      ],
      "metadata": {
        "id": "cY9k2wx-i51r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN Model\n",
        "# Describe CNN layer - 2 layers\n",
        "\n",
        "conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1)\n",
        "conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1)\n"
      ],
      "metadata": {
        "id": "1N3MG2XOmnn9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets grab one MNIST Record/image\n",
        "\n",
        "for i , (X_train, y_train) in enumerate(train_data):\n",
        "    break\n"
      ],
      "metadata": {
        "id": "SKtvweCAnTxS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zynk7G2Entwq",
        "outputId": "e20a051c-ca42-46b0-d3a1-780bf965970c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_train.view(1,1,28,28) # You can use reshape also\n"
      ],
      "metadata": {
        "id": "NhV5QhtXn3bP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform out first convolution\n",
        "\n",
        "x = F.relu(conv1(x)) #Rectified Linear Unit for our activation function"
      ],
      "metadata": {
        "id": "H3kvAmwRoXiD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 1 - Single Image , 6- filters , but dimension has reduced from 28x28 to 26x26 because the convolution got rid of the extra padding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw1PwBbNovcr",
        "outputId": "b7dd4096-ab8d-4b2f-ea03-66f89454e91a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass through the pooling layer\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2) # Kernel Size of 2 and stride size of 2"
      ],
      "metadata": {
        "id": "YrEMEo2WoxCj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 26 /2 = 13 thus pooled 26x26 to 13x13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVQ_uCDip0fW",
        "outputId": "f1adf388-af72-448b-a5f1-cc2f4f672f27"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets do our second convolutional layer\n",
        "\n",
        "x= F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "CFFvR07zqC8O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # lost two pixel on the outside for padding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYt-DA-Eqbv4",
        "outputId": "9f847333-ba44-4e53-c2f2-b4e1eba31d89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling the 2nd convolutional layer\n",
        "\n",
        "x = F.max_pool2d(x, 2, 2)"
      ],
      "metadata": {
        "id": "IoD00L-WqdQn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 11/2 = 5.5 amd we cant rounup because we have lost the data already which cant be recovered and thus we pool dowm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4SrZ3-aqqoM",
        "outputId": "48b6cd8c-9bb1-4af0-b7cd-a21fe16bfb75"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Class\n",
        "\n",
        "class ConvolutionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,6,3,1)\n",
        "    self.conv2 = nn.Conv2d(6,16,3,1)\n",
        "\n",
        "    # implementing fully connected layers\n",
        "    self.fc1 = nn.Linear(5*5*16, 120) # 5*5*16 from the x shape after pooling and 120 is the number of neurons\n",
        "    self.fc2 = nn.Linear(120, 84) # 120 neunrons from previous connected layer to 84 neurons (arbitrary) next\n",
        "    self.fc3 = nn.Linear(84,10) # 84 from previous connected layer to 10 as we have 10 classes of number 0-9\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.conv1(X))\n",
        "    X = F.max_pool2d(X, 2, 2) #2X2 kernal and a stride of 2\n",
        "\n",
        "    # Second Pass\n",
        "    X = F.relu(self.conv2(X))\n",
        "    X = F.max_pool2d(X, 2, 2)\n",
        "\n",
        "    #Re-view to flatten it out\n",
        "\n",
        "    X = X.view(-1, 5*5*16) # Negative so that we can vary the batch size\n",
        "\n",
        "    #Fully connected layers\n",
        "    X = F.relu(self.fc1(X))\n",
        "    X = F.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "    return F.log_softmax(X, dim=1)\n"
      ],
      "metadata": {
        "id": "H8UhuebLqrud"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of our model\n",
        "# Creating a seed\n",
        "\n",
        "torch.manual_seed(41)\n",
        "model = ConvolutionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy2kRqQHwS0n",
        "outputId": "cd0c2e2f-c137-456d-86bc-27bd4efa5f04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNetwork(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # The smaller rate is longer it will time to take"
      ],
      "metadata": {
        "id": "9Aw1M7cPwdII"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time #Just curious how much time it takes\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "#Create variable to track things\n",
        "epochs = 5\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "# For loop for epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "  #Training\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    b+=1 #Start our bacth with 1\n",
        "    y_pred = model(X_train)  # Prediction values from training set\n",
        "    loss = criterion(y_pred, y_train)  # How far off are we from actual\n",
        "    predicted = torch.max(y_pred.data, 1)[1] # Add up numbers for correct prediction\n",
        "    batch_corr = (predicted == y_train).sum() # Sum all correct prediction from this batch. True = 1 and False =0 and we sum those off\n",
        "    trn_corr += batch_corr # Keep a track as we go along in training\n",
        "\n",
        "    # Update our parameters\n",
        "\n",
        "    optimizer.zero_grad() # Reset the gradient\n",
        "    loss.backward() # Back propagation\n",
        "    optimizer.step() # Update the parameters\n",
        "\n",
        "    #Print out some results\n",
        "\n",
        "    if b%600 == 0:\n",
        "      print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "  # Append loss and correct\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "  # Testing\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for b, (X_test, y_test) in enumerate(test_loader):\n",
        "      y_val = model(X_test)\n",
        "      predicted = torch.max(y_val.data, 1)[1]\n",
        "      tst_corr += (predicted == y_test).sum()\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "print(f'Epoch: {i}  Batch: {b}  Loss: {loss.item()}')\n",
        "\n",
        "\n",
        "\n",
        "current = time.time()\n",
        "total_time = current - start_time\n",
        "print(\"The time taken was : \",total_time/60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUNfL-V-wywm",
        "outputId": "d8bc6f19-3b3b-4419-d5db-2bb663c10116"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0  Batch: 600  Loss: 0.1623610556125641\n",
            "Epoch: 0  Batch: 1200  Loss: 0.1502392590045929\n",
            "Epoch: 0  Batch: 1800  Loss: 0.4744560718536377\n",
            "Epoch: 0  Batch: 2400  Loss: 0.14238706231117249\n",
            "Epoch: 0  Batch: 3000  Loss: 0.007758188061416149\n",
            "Epoch: 0  Batch: 3600  Loss: 0.3836284875869751\n",
            "Epoch: 0  Batch: 4200  Loss: 0.0038223876617848873\n",
            "Epoch: 0  Batch: 4800  Loss: 0.0021286322735249996\n",
            "Epoch: 0  Batch: 5400  Loss: 0.0569545142352581\n",
            "Epoch: 0  Batch: 6000  Loss: 0.00038789428072050214\n",
            "Epoch: 1  Batch: 600  Loss: 0.005851339548826218\n",
            "Epoch: 1  Batch: 1200  Loss: 0.3855525553226471\n",
            "Epoch: 1  Batch: 1800  Loss: 0.004819948226213455\n",
            "Epoch: 1  Batch: 2400  Loss: 0.003216963727027178\n",
            "Epoch: 1  Batch: 3000  Loss: 0.0332382395863533\n",
            "Epoch: 1  Batch: 3600  Loss: 0.5372857451438904\n",
            "Epoch: 1  Batch: 4200  Loss: 0.04561494290828705\n",
            "Epoch: 1  Batch: 4800  Loss: 0.0007510822033509612\n",
            "Epoch: 1  Batch: 5400  Loss: 0.0001173773780465126\n",
            "Epoch: 1  Batch: 6000  Loss: 0.14201366901397705\n",
            "Epoch: 2  Batch: 600  Loss: 0.023733172565698624\n",
            "Epoch: 2  Batch: 1200  Loss: 0.003455493599176407\n",
            "Epoch: 2  Batch: 1800  Loss: 0.0008372392621822655\n",
            "Epoch: 2  Batch: 2400  Loss: 0.010705141350626945\n",
            "Epoch: 2  Batch: 3000  Loss: 0.008078320883214474\n",
            "Epoch: 2  Batch: 3600  Loss: 0.0011862406972795725\n",
            "Epoch: 2  Batch: 4200  Loss: 0.038080841302871704\n",
            "Epoch: 2  Batch: 4800  Loss: 0.0016068397089838982\n",
            "Epoch: 2  Batch: 5400  Loss: 0.138673797249794\n",
            "Epoch: 2  Batch: 6000  Loss: 0.2449204921722412\n",
            "Epoch: 3  Batch: 600  Loss: 0.007151054684072733\n",
            "Epoch: 3  Batch: 1200  Loss: 0.011097034439444542\n",
            "Epoch: 3  Batch: 1800  Loss: 0.0017998721450567245\n",
            "Epoch: 3  Batch: 2400  Loss: 0.0001049584461725317\n",
            "Epoch: 3  Batch: 3000  Loss: 0.0031431831885129213\n",
            "Epoch: 3  Batch: 3600  Loss: 0.003668801160529256\n",
            "Epoch: 3  Batch: 4200  Loss: 0.0037249946035444736\n",
            "Epoch: 3  Batch: 4800  Loss: 0.00015864608576521277\n",
            "Epoch: 3  Batch: 5400  Loss: 0.0796482041478157\n",
            "Epoch: 3  Batch: 6000  Loss: 0.0808732658624649\n",
            "Epoch: 4  Batch: 600  Loss: 0.014099588617682457\n",
            "Epoch: 4  Batch: 1200  Loss: 0.0382874570786953\n",
            "Epoch: 4  Batch: 1800  Loss: 0.16302265226840973\n",
            "Epoch: 4  Batch: 2400  Loss: 0.02186887338757515\n",
            "Epoch: 4  Batch: 3000  Loss: 0.0024396399967372417\n",
            "Epoch: 4  Batch: 3600  Loss: 0.0013979513896629214\n",
            "Epoch: 4  Batch: 4200  Loss: 0.000989563181065023\n",
            "Epoch: 4  Batch: 4800  Loss: 0.010317974723875523\n",
            "Epoch: 4  Batch: 5400  Loss: 0.16506639122962952\n",
            "Epoch: 4  Batch: 6000  Loss: 0.0027098222635686398\n",
            "Epoch: 4  Batch: 999  Loss: 0.02076249197125435\n",
            "The time taken was :  3.7422513365745544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6INMdMlb1mvo"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}